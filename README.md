# feedback-bandits
Bandit models with a graph structure
===========================

(See the pdf report in the repo.)

We experiment with RL algorithms for bandits in a graph feedback context inboth the stochastic and adversarial setup.
Our focus is to try and design algorithms for the general feedback graphs in a stochastic context; we present an adaptation of Thompson sampling as well as some algorithms that are inspired from UCB. Both our Thompson and UCB-derived methods produce good experimental results even though we did not derive theoretical upper bounds on the regret.
